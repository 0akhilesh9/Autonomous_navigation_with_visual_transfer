
BASE_TASK_CONFIG_PATH: "/home/userone/workspace/bed1/project/code/config_files/pointnav.yaml"
DATA_PATH_SET: "/home/userone/workspace/bed1/project/habitat-lab/data/datasets/pointnav/gibson/v1/{split}/{split}.json.gz"
SCENE_DIR_SET: "/home/userone/workspace/bed1/project/project_data"
EVAL_CKPT_PATH_DIR: "/home/userone/workspace/bed1/project/tmp/checkpoints"
CHECKPOINT_FOLDER: "/home/userone/workspace/bed1/project/tmp/checkpoints"
VIDEO_DIR: "/home/userone/workspace/bed1/project/tmp/video_dir"
TRAINER_NAME: "ppo"
ENV_NAME: "NavRLEnv"
SIMULATOR_GPU_ID: 0
TORCH_GPU_ID: 0
VIDEO_OPTION: ["disk"]
# To evaluate on all episodes, set this to -1
TEST_EPISODE_COUNT: 10
NUM_PROCESSES: 1
SENSORS: ["RGB_SENSOR"]
#SENSORS: ["RGB_SENSOR", "DEPTH_SENSOR"]
#SENSORS: ["RGB_SENSOR", "SEMANTIC_SENSOR", "DEPTH_SENSOR"]

TASK_CONFIG:
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 500
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: "/home/userone/workspace/bed1/project/project_data/gibson/v1/{split}/{split}.json.gz"
    SCENES_DIR: "/home/userone/workspace/bed1/project/project_data"
    SPLIT: train
    TYPE: PointNav-v1
  SEED: 100
  SIMULATOR:
    AGENT_0:
#      SENSORS: ['RGB_SENSOR', "SEMANTIC_SENSOR", "DEPTH_SENSOR"]

    RGB_SENSOR:
      WIDTH: 256
      HEIGHT: 256
    DEPTH_SENSOR:
      WIDTH: 256
      HEIGHT: 256
    SEMANTIC_SENSOR:
      WIDTH: 256
      HEIGHT: 256
    HABITAT_SIM_V0:
      ALLOW_SLIDING: True
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False

DATASET:
  DATA_PATH: "/home/userone/workspace/bed1/project/project_data/gibson/v1/{split}/{split}.json.gz"
  TYPE: 'PointNav-v1'
  SPLIT: 'train'
  SCENES_DIR: "/home/userone/workspace/bed1/project/project_data"
  CONTENT_SCENES: ['*']

RL:
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.01
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 10.0
  PPO:
    # ppo params
    clip_param: 0.1
    ppo_epoch: 4
    num_mini_batch: 1
    value_loss_coef: 0.5
    entropy_coef: 0.01
    lr: 2.5e-4
    eps: 1e-05
    max_grad_norm: 0.5
    num_steps: 128
    hidden_size: 512
    use_gae: True
    gamma: 0.99
    tau: 0.95
    use_linear_clip_decay: True
    use_linear_lr_decay: True
    reward_window_size: 50
    train:
      VIDEO_OPTION: [ "disk" ]
#      VIDEO_OPTION: []
      num_episodes: 50
      max_steps: 300
      out_filename: ppo_train.csv
      loss_filename: ppo_loss.csv
      checkpoint_save: 10
    test:
      VIDEO_OPTION: [ "disk" ]
      num_episodes: 20
      max_steps: 300
      out_filename: ppo_eval.csv

  DQN:
    clip_param: 0.1
    dqn_epoch: 3
    num_mini_batch: 1
    value_loss_coef: 0.5
    entropy_coef: 0.01
    lr: 2.5e-2
    eps: 0.00001
    max_grad_norm: 0.5
    num_steps: 128
    hidden_size: 512
    use_gae: True
    gamma: 0.99
    tau: 0.95
    use_linear_clip_decay: True
    use_linear_lr_decay: True
    use_normalized_advantage: False
    reward_window_size: 50
    start_eps: 0.9
    end_eps: 0.1
    max_random_action_steps: 100
    num_episodes: 10
    max_steps: 1000
    log_interval: 10
    checkpoint_interval: 50
    update_frequency: 10
    batch_size: 5
    rnn_seq_len: 5
    discount_factor: 0.99
    save_path: "/home/userone/workspace/bed1/project/code/models/trained/dqn.pth"
    train:
      VIDEO_OPTION: [ "disk" ]
#      VIDEO_OPTION: []
      num_episodes: 50
      max_steps: 300
      out_filename: dqn_train.csv
      loss_filename: dqn_loss.csv
      checkpoint_save: 10
    test:
      VIDEO_OPTION: [ "disk" ]
      num_episodes: 20
      max_steps: 300
      out_filename: dqn_eval.csv

